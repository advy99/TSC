{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CLASIFICACIÓN DEL RIESGO DE ABANDONO DE LOS CLIENTES DE UN BANCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos con el que vamos a trabajar ahora contiene información sobre los usuarios de un banco. Queremos predecir si los clientes van a dejar de usar los servicios de dicho banco o no. El conjunto de datos consta de 10000 observaciones y 14 variables.\n",
    "\n",
    "La siguiente figura indica cómo cargar el conjunto de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una matriz con las variables de entrada y otra matriz con la variable de salida (objetivo, columna 14). Excluiremos la columna 1 y 2 que son ‘row_number’ y ‘customerid’ ya que no nos aportan información útil para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,3:13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', 41, 1, 83807.86, 1, 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', 42, 8, 159660.8, 3, 1, 0, 113931.57],\n",
       "       [699, 'France', 'Female', 39, 1, 0.0, 2, 0, 0, 93826.63]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer el análisis más sencillo si codificamos las variables no numéricas. Country contiene los valores: ’France, Spain, Germany’ y Gender: ‘Male, Female’. La manera de codificarlo será convertir estas palabras a valores numéricos. Para esto usaremos la función LabelEncoder, de la librería ‘ScikitLearn’, que al darle una cadena de texto nos devuelve valores entre 0 y n_clases-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que Country ahora toma valores del 0 al 2 mientras que male y female fueron reemplazados por 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la función train_test_split de la librería ScikitLearn para dividir nuestros datos.\n",
    "\n",
    "Usaremos 80% para entrenar el modelo y 20% para validarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[709, 1, 1, ..., 1, 0, 145251.35],\n",
       "        [786, 2, 0, ..., 1, 0, 117034.32],\n",
       "        [648, 1, 0, ..., 1, 0, 190994.48],\n",
       "        ...,\n",
       "        [666, 0, 0, ..., 1, 0, 50908.48],\n",
       "        [695, 0, 0, ..., 1, 1, 141756.32],\n",
       "        [595, 1, 1, ..., 1, 0, 48421.4]], dtype=object),\n",
       " array([[684, 0, 1, ..., 1, 1, 71725.73],\n",
       "        [447, 0, 0, ..., 1, 1, 151815.76],\n",
       "        [485, 1, 1, ..., 1, 0, 51113.14],\n",
       "        ...,\n",
       "        [660, 0, 1, ..., 1, 0, 13218.6],\n",
       "        [550, 0, 1, ..., 1, 1, 133501.94],\n",
       "        [585, 0, 1, ..., 1, 1, 55346.14]], dtype=object),\n",
       " array([0, 0, 1, ..., 0, 0, 1]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si observamos los datos detenidamente podemos apreciar que hay variables cuyos valores pueden\n",
    "ser muy variados, desde muy altos a muy pequeños por esta razón escalaremos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.60628195,  0.29962659,  0.91094795, ...,  0.64959174,\n",
       "         -1.03797037,  0.78365451],\n",
       "        [ 1.41054777,  1.50234244, -1.09775756, ...,  0.64959174,\n",
       "         -1.03797037,  0.29178878],\n",
       "        [-0.0308637 ,  0.29962659, -1.09775756, ...,  0.64959174,\n",
       "         -1.03797037,  1.58102679],\n",
       "        ...,\n",
       "        [ 0.15714649, -0.90308927, -1.09775756, ...,  0.64959174,\n",
       "         -1.03797037, -0.86088511],\n",
       "        [ 0.4600518 , -0.90308927, -1.09775756, ...,  0.64959174,\n",
       "          0.96341863,  0.72273082],\n",
       "        [-0.58444927,  0.29962659,  0.91094795, ...,  0.64959174,\n",
       "         -1.03797037, -0.9042387 ]]),\n",
       " array([[ 0.34515668, -0.90308927,  0.91094795, ...,  0.64959174,\n",
       "          0.96341863, -0.49800881],\n",
       "        [-2.13031084, -0.90308927, -1.09775756, ...,  0.64959174,\n",
       "          0.96341863,  0.89808215],\n",
       "        [-1.73340044,  0.29962659,  0.91094795, ...,  0.64959174,\n",
       "         -1.03797037, -0.85731758],\n",
       "        ...,\n",
       "        [ 0.09447643, -0.90308927,  0.91094795, ...,  0.64959174,\n",
       "         -1.03797037, -1.51787701],\n",
       "        [-1.05447474, -0.90308927,  0.91094795, ...,  0.64959174,\n",
       "          0.96341863,  0.57884443],\n",
       "        [-0.68889937, -0.90308927,  0.91094795, ...,  0.64959174,\n",
       "          0.96341863, -0.78352996]]),\n",
       " array([0, 0, 1, ..., 0, 0, 1]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez escalados los datos, pasamos a construir la red neuronal. Importamos Keras, usamos el módulo Sequential para inicializar la red y el modelo Dense para añadir capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la red con Sequential()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 19:20:52.793280: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 19:20:52.794404: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos las capas usando la función Dense. Indicamos el número de nodos que queremos añadir con output_dim, Init es la inicialización del descenso de gradiente estocástico. Los pesos iniciales serán una variable aleatoria uniforme. Input_dim sólo es necesaria en la primera capa para que el modelo sepa la cantidad de variables que va a recibir, en nuestro caso 11. A partir de aquí las siguientes capas heredarán esta cualidad de la primera capa. La función de activación que utilizaremos será relu en las dos primeras capas (cuanto más cerca tenga su valor a 1, la neurona estará más activada y tendrá más interacción) y en la capa final hemos utilizado la función sigmoide ya que nuestro objetivo es clasificar.\n",
    "\n",
    "Una vez que tenemos la configuración específica de la red, la siguiente tarea es compilarla, para eso utilizamos la función Compile. El primer argumento de esta función es Optimizer que indica el método para entrenar los pesos. Adam es un algoritmo que se basa en el cálculo del descenso del Gradiente Estocástico. El segundo parámetro es loss, este usará la función ‘binary_crossentropy’ para clasificar en 2 categorías. Si tuviéramos más categorías utilizaríamos la función ‘categorical_crossentropy’. Para saber la bondad de nuestra red neuronal utilizaremos la métrica accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(6, activation = 'relu', input_shape = (10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la función fit para ajustar los pesos de la red. Batch_size para especificar el número de observaciones que necesita entrenar antes de actualizar los pesos. Epoch nos indica el número de iteraciones que realizaremos en el entrenamiento. La estimación de estos parámetros se tiene que hacer por ensayo-error, probando con diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 33s 4ms/sample - loss: 0.4423 - accuracy: 0.8056\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 32s 4ms/sample - loss: 0.3724 - accuracy: 0.8454\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 32s 4ms/sample - loss: 0.3643 - accuracy: 0.8489\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 32s 4ms/sample - loss: 0.3598 - accuracy: 0.8514\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 32s 4ms/sample - loss: 0.3558 - accuracy: 0.8516\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 34s 4ms/sample - loss: 0.3532 - accuracy: 0.8539\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 41s 5ms/sample - loss: 0.3507 - accuracy: 0.8534\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 0.3475 - accuracy: 0.8575\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 0.3471 - accuracy: 0.8591\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 34s 4ms/sample - loss: 0.3458 - accuracy: 0.8575\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 34s 4ms/sample - loss: 0.3451 - accuracy: 0.8581\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 35s 4ms/sample - loss: 0.3439 - accuracy: 0.8576\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 35s 4ms/sample - loss: 0.3433 - accuracy: 0.8621\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 34s 4ms/sample - loss: 0.3434 - accuracy: 0.8570\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 35s 4ms/sample - loss: 0.3434 - accuracy: 0.8596\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 35s 4ms/sample - loss: 0.3419 - accuracy: 0.8576\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 36s 4ms/sample - loss: 0.3419 - accuracy: 0.8586\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 36s 4ms/sample - loss: 0.3427 - accuracy: 0.8605\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 36s 4ms/sample - loss: 0.3412 - accuracy: 0.8585\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 36s 5ms/sample - loss: 0.3408 - accuracy: 0.8575\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 36s 4ms/sample - loss: 0.3412 - accuracy: 0.8584\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 36s 5ms/sample - loss: 0.3415 - accuracy: 0.8584\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 36s 4ms/sample - loss: 0.3406 - accuracy: 0.8568\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 0.3404 - accuracy: 0.8612\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 74s 9ms/sample - loss: 0.3396 - accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 89s 11ms/sample - loss: 0.3386 - accuracy: 0.8605\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 66s 8ms/sample - loss: 0.3389 - accuracy: 0.8576\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.3380 - accuracy: 0.8608\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 69s 9ms/sample - loss: 0.3370 - accuracy: 0.8586\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 5998s 750ms/sample - loss: 0.3377 - accuracy: 0.8611\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 86s 11ms/sample - loss: 0.3364 - accuracy: 0.8575\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 91s 11ms/sample - loss: 0.3356 - accuracy: 0.8615\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 95s 12ms/sample - loss: 0.3363 - accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.3358 - accuracy: 0.8601\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 82s 10ms/sample - loss: 0.3348 - accuracy: 0.8621\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 81s 10ms/sample - loss: 0.3350 - accuracy: 0.8606\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.3357 - accuracy: 0.8583\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 91s 11ms/sample - loss: 0.3356 - accuracy: 0.8600\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 80s 10ms/sample - loss: 0.3350 - accuracy: 0.8594\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 94s 12ms/sample - loss: 0.3343 - accuracy: 0.8631\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 84s 11ms/sample - loss: 0.3346 - accuracy: 0.8609\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 93s 12ms/sample - loss: 0.3343 - accuracy: 0.8594\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 70s 9ms/sample - loss: 0.3339 - accuracy: 0.8619\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.3345 - accuracy: 0.8618\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 86s 11ms/sample - loss: 0.3343 - accuracy: 0.8591\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 83s 10ms/sample - loss: 0.3333 - accuracy: 0.8620\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.3330 - accuracy: 0.8620\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 55s 7ms/sample - loss: 0.3335 - accuracy: 0.8633\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 59s 7ms/sample - loss: 0.3325 - accuracy: 0.8616\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 58s 7ms/sample - loss: 0.3321 - accuracy: 0.8605\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 58s 7ms/sample - loss: 0.3320 - accuracy: 0.8633\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 60s 7ms/sample - loss: 0.3324 - accuracy: 0.8629\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.3331 - accuracy: 0.8619\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.3327 - accuracy: 0.8630\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.3326 - accuracy: 0.8611\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 68s 8ms/sample - loss: 0.3312 - accuracy: 0.8658\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 59s 7ms/sample - loss: 0.3328 - accuracy: 0.8624\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 58s 7ms/sample - loss: 0.3327 - accuracy: 0.8624\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.3313 - accuracy: 0.8620\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.3307 - accuracy: 0.8629\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 72s 9ms/sample - loss: 0.3324 - accuracy: 0.8651\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 105s 13ms/sample - loss: 0.3314 - accuracy: 0.8627\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 97s 12ms/sample - loss: 0.3319 - accuracy: 0.8616\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 81s 10ms/sample - loss: 0.3314 - accuracy: 0.8635\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 49s 6ms/sample - loss: 0.3314 - accuracy: 0.8637\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 49s 6ms/sample - loss: 0.3308 - accuracy: 0.8633\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.3309 - accuracy: 0.8639\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 57s 7ms/sample - loss: 0.3319 - accuracy: 0.8641\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 54s 7ms/sample - loss: 0.3310 - accuracy: 0.8641\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 45s 6ms/sample - loss: 0.3313 - accuracy: 0.8640\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 82s 10ms/sample - loss: 0.3308 - accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 100s 12ms/sample - loss: 0.3322 - accuracy: 0.8625\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 107s 13ms/sample - loss: 0.3300 - accuracy: 0.8616\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 85s 11ms/sample - loss: 0.3310 - accuracy: 0.8624\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 83s 10ms/sample - loss: 0.3298 - accuracy: 0.8639\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 92s 12ms/sample - loss: 0.3314 - accuracy: 0.8640\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 67s 8ms/sample - loss: 0.3307 - accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 70s 9ms/sample - loss: 0.3307 - accuracy: 0.8622\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 76s 10ms/sample - loss: 0.3316 - accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 67s 8ms/sample - loss: 0.3303 - accuracy: 0.8637\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 3313s 414ms/sample - loss: 0.3313 - accuracy: 0.8621\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 117s 15ms/sample - loss: 0.3305 - accuracy: 0.8635\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 53s 7ms/sample - loss: 0.3305 - accuracy: 0.8627\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 73s 9ms/sample - loss: 0.3308 - accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 88s 11ms/sample - loss: 0.3298 - accuracy: 0.8631\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 85s 11ms/sample - loss: 0.3292 - accuracy: 0.8656\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 81s 10ms/sample - loss: 0.3303 - accuracy: 0.8651\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.3301 - accuracy: 0.8634\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 85s 11ms/sample - loss: 0.3298 - accuracy: 0.8626\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.3308 - accuracy: 0.8627\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 59s 7ms/sample - loss: 0.3310 - accuracy: 0.8626\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.3314 - accuracy: 0.8614\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 79s 10ms/sample - loss: 0.3296 - accuracy: 0.8636\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 88s 11ms/sample - loss: 0.3307 - accuracy: 0.8625\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 86s 11ms/sample - loss: 0.3301 - accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.3304 - accuracy: 0.8644\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 290s 36ms/sample - loss: 0.3305 - accuracy: 0.8620\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.3298 - accuracy: 0.8634\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 78s 10ms/sample - loss: 0.3302 - accuracy: 0.8615\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 0.3283 - accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbb58b80d90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la predicción sobre nuestro conjunto de test lo haremos mediante la siguiente expresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción nos proporcionará la probabilidad de pertenecer a un grupo u otro, de tal manera que aquellos valores mayores que 0.5 serán 1 y el resto 0.\n",
    "\n",
    "Creamos una matriz de confusión y vemos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1533,   54],\n",
       "       [ 206,  207]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1587\n",
      "           1       0.79      0.50      0.61       413\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2000\n",
      "   macro avg       0.84      0.73      0.77      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
